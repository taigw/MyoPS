[dataset]
# tensor type (float or double)
tensor_type = float

root_dir  = /mnt/39E12DAE493BA6C1/datasets/MyoPS_test/data_preprocessed
train_csv = myops/config/data_train/fold_5/image_train.csv
valid_csv = myops/config/data_train/fold_5/image_valid.csv
test_csv  = myops/config/data_train/fold_5/image_test.csv
# test_csv  = myops/config/data_test/image_test.csv

# modality number
modal_num = 3

# data transforms
train_transform = [ChannelWiseNormalize, RandomFlip, RandomRotate, RandomCrop, LabelConvert, LabelToProbability]
test_transform  = [ChannelWiseNormalize, Pad]

ChannelWiseNormalize_mean = None
ChannelWiseNormalize_std  = None
ChannelWiseNormalize_channels = [0, 1, 2]
ChannelWiseNormalize_zero_to_random = False
ChannelWiseNormalize_inverse = False

RandomRotate_angle_range_d = [-30, 30]
RandomRotate_angle_range_h = None
RandomRotate_angle_range_w = None
RandomRotate_inverse = True

RandomFlip_flip_depth = False
RandomFlip_flip_height = True
RandomFlip_flip_width = True
RandomFlip_inverse = True

RandomCrop_output_size = [1, 160, 160]
RandomCrop_foreground_focus = False
RandomCrop_foreground_ratio = 0.5
Randomcrop_mask_label       = [1]
RandomCrop_inverse     = False

LabelConvert_source_list = [1, 2, 3, 4, 5]
LabelConvert_target_list = [1, 2, 3, 1, 1]
LabelConvert_inverse = False

LabelToProbability_class_num = 4
LabelToProbability_inverse   = False

# Do not pad images along D dimension
Pad_output_size = [1, 16, 16]
Pad_ceil_mode = True
Pad_inverse = True

[network]
# this section gives parameters for network
# the keys may be different for different networks

# type of network
net_type = UNet2D

# number of class, required for segmentation task
class_num     = 4
in_chns       = 3
feature_chns  = [16, 32, 64, 128, 256]
# dropout       = [0, 0, 0, 0, 0]
dropout       = [0, 0, 0.5, 0.5, 0.5]
bilinear     = False

[training]
# device name cuda:n or cpu
deterministic = True
device_name = cuda:0

batch_size  = 1
loss_function = ce_dice_loss

# for optimizers
optimizer     = SGD
learning_rate = 6e-3
momentum      = 0.9
weight_decay  = 1e-6

# for lr schedular (MultiStepLR)
lr_gamma      = 0.5
lr_milestones = [3000, 6000, 9000, 12000]

summary_dir  = myops/model_train/unet2d/fold_5/
checkpoint_prefix = myops/model_train/unet2d/fold_5/model

# start iter
iter_start = 0
iter_max   = 16000
iter_valid = 100
iter_save = [4000, 8000, 12000, 15200, 15400, 15600, 15800, 16000]

[testing]
# device name cuda:n or cpu
device_name = cuda:0

# ensemble of multiple checkpoints
checkpoint_list  = [15200, 15400, 15600, 15800, 16000]
output_dir        = myops/result_train/unet2d/fold_5/
# output_dir        = myops/result_test/unet2d/
evaluation_mode   = True
test_time_dropout = False

label_source = None
label_target = None
filename_replace_source = _C0.nii.gz
filename_replace_target = .nii.gz

mini_batch_size         = 64
# mini_patch_input_shape  = [None, 160, 160]
# mini_patch_output_shape = [None, 80, 80]
# mini_patch_stride       = [None, 80, 80]

mini_patch_input_shape  = None
mini_patch_output_shape = None
mini_patch_stride       = None
